{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eca5b4bc-d44f-4094-8c07-08ea0c37b415",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed634bfe-958d-4873-8ac1-b99ed7f6394e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install imbalanced-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dafee470-8290-4109-8029-6e96c921f609",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8fad166-10eb-4289-9d7e-836fb36c7496",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('logistic_regression.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02638bcf-132e-433a-8c40-ff58b3d868c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d38ee9e-ac41-4975-8731-75f99573f4d3",
   "metadata": {},
   "source": [
    "### Problem Statement\n",
    "\n",
    "LoanTap seeks to develop an underwriting system to assess the creditworthiness of individuals applying for a **Personal Loan**. Given a set of applicant attributes (demographics, employment, financial history, and credit behavior), the system should address two key objectives:\n",
    "1. **Loan Decisioning** – Determine whether the loan application should be **approved or rejected** based on the applicant’s creditworthiness.  \n",
    "2. **Repayment Recommendation** – For approved applicants, recommend **suitable loan terms** (loan amount, tenure, and interest rate) that balance:  \n",
    "   - **Customer affordability**  \n",
    "   - **LoanTap’s risk management objectives**  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbe90969-d661-49e6-a12c-30f3372171d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d3860d6-418c-4a15-a065-c9fa79689b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4406caf9-5383-4fda-92b7-4a6ddc9357b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1755d44-6e3b-4221-895f-227f5c296f7c",
   "metadata": {},
   "source": [
    "#### ==========================\n",
    "### Data Analysis\n",
    "#### =========================="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5af83d3c-8ab0-43ff-9795-705f305458c2",
   "metadata": {},
   "source": [
    "#### Shape of Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2dbb856-9f2a-49b2-9456-7c2fa41bfca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Shape of dataset:\", df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5efb30ac-a894-408d-81c3-79c54068dcc5",
   "metadata": {},
   "source": [
    "#### Data Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4d1f3ef-8fec-4b14-86fe-5715a98392e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nData Types:\\n\", df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42cf3dc3-3e73-453d-a79d-92897284b362",
   "metadata": {},
   "source": [
    "#### Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62db113f-10df-48e6-89ed-51f7de27376b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nMissing Values:\\n\", df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77953291-c74a-485b-baac-07a1371817bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert Categorical Columns to 'category'\n",
    "categorical_cols = df.select_dtypes(include=['object']).columns\n",
    "# Drop date-like fields from categorical\n",
    "categorical_cols = [col for col in categorical_cols if col not in ['issue_d', 'earliest_cr_line','address','emp_length']]\n",
    "\n",
    "for col in categorical_cols:\n",
    "    df[col] = df[col].astype('category')\n",
    "\n",
    "print(\"\\nCategorical columns converted to 'category':\", categorical_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ea56a18-152b-41a7-a25d-2f24e73bde25",
   "metadata": {},
   "source": [
    "#### Statistical Summary (Numerical Attributes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f4e0de5-fcc5-4ca2-a8c8-e8db35a1ceff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================\n",
    "\n",
    "# ======================\n",
    "print(\"\\nStatistical Summary:\\n\")\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f5e8f47-6b7f-405a-96bc-f9e57bfdf401",
   "metadata": {},
   "source": [
    "#### Missing Value Treatment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e33ac701-0926-4c4c-9f50-57b331cc0e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nMissing Values:\\n\",)\n",
    "df.isnull().sum()[df.isnull().sum() > 0].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01480ade-db11-4e62-8b38-68a096b7ee4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71298fce-7c20-45e5-86f1-ba1a5b5f1cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nMissing Values:\\n\",)\n",
    "df.isnull().sum()[df.isnull().sum() > 0].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58de3bd2-2a1c-47f4-bb0f-0017e7ef5bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=['title'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a877163-14ce-4ab7-9106-bad0cf2b3f21",
   "metadata": {},
   "source": [
    "#### Outlier Treatment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fcf12b9-0052-4211-992b-b49a02447e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Columns to check for outliers\n",
    "num_cols = ['open_acc', 'pub_rec', 'revol_bal', 'total_acc', 'pub_rec_bankruptcies', 'dti', 'loan_amnt', 'installment', 'annual_inc']\n",
    "\n",
    "# Copy the dataframe\n",
    "outlier_removed_df = df.copy()\n",
    "\n",
    "# Remove outliers using IQR method\n",
    "for col in num_cols:\n",
    "    Q1 = outlier_removed_df[col].quantile(0.25)\n",
    "    Q3 = outlier_removed_df[col].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    # Keep only rows within the IQR bounds\n",
    "    outlier_removed_df = outlier_removed_df[(outlier_removed_df[col] >= lower_bound) & (outlier_removed_df[col] <= upper_bound)]\n",
    "\n",
    "# Check the resulting dataframe\n",
    "outlier_removed_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33928e48-569a-4737-b4ee-816a5626ce36",
   "metadata": {},
   "source": [
    "#### Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b5fdf34-602a-41eb-8e88-45d0d9ee1f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def binarize_features(df, cols):\n",
    "    df_copy = df.copy()\n",
    "    for col in cols:\n",
    "        df_copy[col] = df_copy[col].apply(lambda x: 0 if x == 0 else 1)\n",
    "    return df_copy\n",
    "\n",
    "binary_cols = ['pub_rec', 'mort_acc', 'pub_rec_bankruptcies']\n",
    "\n",
    "binarized_df = binarize_features(outlier_removed_df, binary_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3deaa6b4-8e3e-456b-84d8-4d11061be1f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def categorize_job(title):\n",
    "    if pd.isnull(title) or str(title).strip() == '':\n",
    "        return \"Unknown\"\n",
    "    \n",
    "    title = str(title).lower()\n",
    "\n",
    "    # Define keyword-based rules with expanded coverage\n",
    "    if re.search(r\"teacher|professor|instructor|principal|educator|tutor\", title):\n",
    "        return \"Education\"\n",
    "    elif re.search(r\"nurse|rn|lpn|cna|healthcare|physician|doctor|pharmacist|medical|clinic|hospital\", title):\n",
    "        return \"Healthcare\"\n",
    "    elif re.search(r\"driver|truck|transport|operator|delivery|chauffeur\", title):\n",
    "        return \"Transport\"\n",
    "    elif re.search(r\"engineer|developer|programmer|coder|software|technician|network|it|data|systems\", title):\n",
    "        return \"Technology\"\n",
    "    elif re.search(r\"manager|supervisor|director|vp|president|executive|superintendent|controller|coordinator|administrator|lead\", title):\n",
    "        return \"Management\"\n",
    "    elif re.search(r\"accountant|auditor|finance|analyst|advisor|bookkeeper|underwriter|controller|cfo|financial|treasurer\", title):\n",
    "        return \"Finance\"\n",
    "    elif re.search(r\"sales|marketing|customer|associate|representative|clerk|cashier|retail|merchandiser|store\", title):\n",
    "        return \"Sales/Marketing\"\n",
    "    elif re.search(r\"legal|attorney|paralegal|lawyer|counsel|judge\", title):\n",
    "        return \"Legal\"\n",
    "    elif re.search(r\"military|us army|usaf|navy|air force|marine|coast guard|soldier|veteran\", title):\n",
    "        return \"Military\"\n",
    "    elif re.search(r\"police|officer|firefighter|security|sheriff|corrections\", title):\n",
    "        return \"Public Safety\"\n",
    "    elif re.search(r\"mechanic|electrician|machinist|construction|foreman|plumber|welder|carpenter|technician|hvac\", title):\n",
    "        return \"Skilled Trade\"\n",
    "    elif re.search(r\"real estate|realtor|broker|property|leasing\", title):\n",
    "        return \"Real Estate\"\n",
    "    elif re.search(r\"bank|loan|mortgage|credit union\", title):\n",
    "        return \"Banking\"\n",
    "    elif re.search(r\"hr|human resources|recruiter|talent|staffing\", title):\n",
    "        return \"HR/Recruitment\"\n",
    "    elif re.search(r\"server|waiter|waitress|bartender|cook|chef|hospitality|hotel|restaurant\", title):\n",
    "        return \"Hospitality\"\n",
    "    elif re.search(r\"government|federal|state|county|city|public works|council\", title):\n",
    "        return \"Government\"\n",
    "    else:\n",
    "        return \"Other\"\n",
    "\n",
    "engg_df = binarized_df.copy()\n",
    "# Apply function\n",
    "engg_df['emp_category'] = engg_df['emp_title'].apply(categorize_job)\n",
    "\n",
    "# Check distribution\n",
    "print(engg_df['emp_category'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c477fd3-6674-477c-b052-9ef46e9c73d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "engg_df['emp_length'].value_counts().reset_index()\n",
    "\n",
    "emp_length_map = {\n",
    "    '10+ years': 10,\n",
    "    '9 years': 9,\n",
    "    '8 years': 8,\n",
    "    '7 years': 7,\n",
    "    '6 years': 6,\n",
    "    '5 years': 5,\n",
    "    '4 years': 4,\n",
    "    '3 years': 3,\n",
    "    '2 years': 2,\n",
    "    '1 year': 1,\n",
    "    '< 1 year': 0\n",
    "}\n",
    "# Replace with mapping\n",
    "engg_df['emp_length'] = engg_df['emp_length'].map(emp_length_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c4b7a2a-d3c4-43c8-ab1f-e5f3c0c134a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "engg_df.describe(include=[object, 'category'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43a0c68f-d7af-4159-8bea-4f1ea2f92e05",
   "metadata": {},
   "source": [
    "#### Univariate Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c25332d5-c65b-482b-8aa8-6a6aa1f7a3b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "engg_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b64af2-9551-4695-a8fc-4fe37da0dce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "\n",
    "# sns.set(style=\"whitegrid\", palette=\"muted\")\n",
    "# plt.rcParams[\"figure.figsize\"] = (10, 5)\n",
    "# plt.rcParams['font.family'] = 'DejaVu Sans' \n",
    "# plt.rcParams['text.usetex'] = False\n",
    "# plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "# # Continuous Variables\n",
    "# num_cols = engg_df.select_dtypes(include=['float64', 'int64']).columns\n",
    "\n",
    "# for col in num_cols:\n",
    "#     plt.figure()\n",
    "#     sns.histplot(engg_df[col].dropna(), kde=True, bins=30)\n",
    "#     plt.title(f\"Distribution of {col}\")\n",
    "#     plt.xlabel(col)\n",
    "#     plt.ylabel(\"Frequency\")\n",
    "#     plt.show()\n",
    "\n",
    "# categorical_cols = ['grade','sub_grade','home_ownership','verification_status','purpose','emp_category','initial_list_status']\n",
    "\n",
    "# # Categorical Variables\n",
    "# for col in categorical_cols:\n",
    "#     plt.figure()\n",
    "#     sns.countplot(data=engg_df, x=col, order=engg_df[col].value_counts().index)\n",
    "#     plt.title(f\"Countplot of {col}\")\n",
    "#     plt.xticks(rotation=45)\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "604d046d-f172-42d5-b154-30fc1f298058",
   "metadata": {},
   "source": [
    "#### Bivariate Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55bda198-7318-4658-b3e9-d29ae13a613e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# target = 'loan_status'\n",
    "\n",
    "# # Numerical vs Target\n",
    "# for col in num_cols:\n",
    "#     plt.figure()\n",
    "#     sns.boxplot(data=engg_df, x=target, y=col)\n",
    "#     plt.title(f\"{col} vs {target}\")\n",
    "#     plt.show()\n",
    "\n",
    "# # Categorical vs Target\n",
    "# for col in categorical_cols:\n",
    "#     plt.figure()\n",
    "#     sns.countplot(data=engg_df, x=col, hue=target, order=engg_df[col].value_counts().index)\n",
    "#     plt.title(f\"{col} vs {target}\")\n",
    "#     plt.xticks(rotation=45)\n",
    "#     plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2c6f2ab-8459-493c-be7d-c2803fcbb4ab",
   "metadata": {},
   "source": [
    "#### Data Preparation for Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35a9ba53-d334-4a59-a993-1bd7ea57b0b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "engg_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11ed92b7-c3cb-4ab7-b2b2-63c1974857ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select categorical columns\n",
    "categorical_cols = engg_df.select_dtypes(include=['object', 'category']).columns\n",
    "\n",
    "for col in categorical_cols:\n",
    "    unique_vals = engg_df[col].unique()\n",
    "    print(f\"Column: {col}\")\n",
    "    print(f\"Number of unique values: {len(unique_vals)}\")\n",
    "    print(f\"Unique values (sample up to 20): {unique_vals[:20]}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7188ddc4-54f1-4d42-884c-fe14b1625aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "engg_df['term'] = engg_df['term'].map({' 36 months': 36, ' 60 months': 60})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9df69165-4ac8-4e24-88b4-355cc5c04f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# engg_df['state'] = engg_df['address'].apply(lambda x: x.split()[-2] if pd.notnull(x) else 'Unknown')\n",
    "import re\n",
    "\n",
    "def extract_zip(address):\n",
    "    # Find the last 5 consecutive digits in the string\n",
    "    match = re.search(r'(\\d{5})(?!.*\\d)', address)\n",
    "    return match.group(1) if match else None\n",
    "\n",
    "# Apply to your DataFrame column (say 'address')\n",
    "engg_df['zipcode'] = engg_df['address'].apply(extract_zip)\n",
    "\n",
    "# # Check result\n",
    "# print(engg_df[['address', 'zipcode']].head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3121360-c47e-4f9e-b453-b3f9cfdf0b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_cols = ['purpose', 'verification_status', \n",
    "                    'home_ownership', 'grade','zipcode']\n",
    "# 'sub_grade','emp_category','state'removed for now\n",
    "# Create dummies for all columns at once, drop first category, and ensure 0/1\n",
    "engg_df = pd.get_dummies(engg_df, columns=categorical_cols, drop_first=True)\n",
    "\n",
    "# Convert any boolean columns (True/False) to 0/1\n",
    "bool_cols = engg_df.select_dtypes(include='bool').columns\n",
    "\n",
    "print(bool_cols)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "183f6f4f-163e-4c54-9fbf-dc945c0ea23b",
   "metadata": {},
   "outputs": [],
   "source": [
    "engg_df[bool_cols] = engg_df[bool_cols].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "697bb4ec-36d1-424d-bef7-a7da75addcfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "engg_df['initial_list_status'] = engg_df['initial_list_status'].map({'f': 0, 'w': 1},)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "667604c0-7aba-4615-85bd-033bdd0efb1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mapping = {'INDIVIDUAL': 0, 'JOINT': 1, 'DIRECT_PAY': 2}\n",
    "# outlier_trtd_df['application_type_encoded'] = outlier_trtd_df['application_type'].map(mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a2085a4-e8be-4206-b316-15db3034df5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert earliest credit line to datetime (Removed for now)\n",
    "# engg_df['earliest_cr_line'] = pd.to_datetime(engg_df['earliest_cr_line'], format='%b-%Y', errors='coerce')\n",
    "\n",
    "# # Create credit history in years (continuous)\n",
    "# engg_df['credit_history_years'] = (pd.to_datetime('today') - engg_df['earliest_cr_line']).dt.days / 365"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "052b3abc-165c-4611-bb1a-122253d806e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_df = engg_df.drop(columns=['earliest_cr_line','address','application_type','issue_d','emp_title','installment','sub_grade','emp_category','emp_length'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef013259-11bd-4a9e-8092-67cacc1cc82f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_columns = None\n",
    "encoded_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fcb1fbe-ad71-40e7-bb39-e2587d2ec79d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bool_cols = encoded_df.select_dtypes(include='bool').columns\n",
    "# print(bool_cols)\n",
    "# encoded_df[bool_cols] = encoded_df[bool_cols].astype(int)\n",
    "# encoded_df[bool_cols].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fe5aae5-55e0-4692-aeae-a9b110188d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_df['loan_status'] = encoded_df['loan_status'].map({'Charged Off': 1, 'Fully Paid': 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3871a843-b8bf-40c5-8833-316066f58b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X = encoded_df.drop(columns=['loan_status'])  # Features\n",
    "y = encoded_df['loan_status']                 # Target\n",
    "\n",
    "feature_names = X.columns \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae3ad6d2-a5b5-4ca5-9cfe-d9e48046be92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# string_cols = X_train.select_dtypes(include=['object', 'string']).columns\n",
    "\n",
    "# print(\"String columns in X_train:\")\n",
    "# print(list(string_cols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faeb1e0e-c4d7-4612-afc2-d3f714419c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.DataFrame(X_train,columns=X.columns )\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7bf574b-cd58-494c-8bff-9d503b7f5c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "# ---------------------\n",
    "# 4. Logistic Regression\n",
    "# ---------------------\n",
    "clf = LogisticRegression(max_iter=1000)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# ---------------------\n",
    "# 5. Evaluate\n",
    "# ---------------------\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64c8afa2-efd3-42f9-9068-0688ae7c5bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "\n",
    "# # Get feature importance from logistic regression\n",
    "# feature_importance = pd.DataFrame({\n",
    "#     'Feature': feature_names,\n",
    "#     'Coefficient': log_reg.coef_[0],\n",
    "#     'Abs_Coefficient': np.abs(log_reg.coef_[0])\n",
    "# }).sort_values(by='Abs_Coefficient', ascending=False)\n",
    "\n",
    "# print(feature_importance.head(20))  # Top 20 most important features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59bc08bf-662f-4c2e-a701-4b600e7c4d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Basic SMOTE (works when all features are numeric)\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_res, y_train_res = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "print(\"Before SMOTE:\\n\", y_train.value_counts())\n",
    "print(\"After SMOTE:\\n\", y_train_res.value_counts())\n",
    "\n",
    "# Train Logistic Regression on resampled data\n",
    "log_reg = LogisticRegression(class_weight=\"balanced\")\n",
    "log_reg.fit(X_train_res, y_train_res)\n",
    "\n",
    "# Predictions\n",
    "y_pred = log_reg.predict(X_test)\n",
    "\n",
    "# Evaluation\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\\n\", cm)\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2e53a19-de75-4a96-8087-236e943a0463",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Check for NaN values column-wise\n",
    "# nan_counts = pd.DataFrame({\n",
    "#     \"missing_count\": X_train_res.isna().sum(),\n",
    "#     \"missing_ratio\": X_train_res.isna().mean()\n",
    "# })\n",
    "\n",
    "# print(\"Total NaN values in resampled data:\", X_train_res.isna().sum().sum())\n",
    "# print(nan_counts[nan_counts[\"missing_count\"] > 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30276f74-d10b-45dd-a42a-4b486446b29c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Evaluation\n",
    "# cm = confusion_matrix(y_test, y_pred)\n",
    "# print(\"Confusion Matrix:\\n\", cm)\n",
    "# print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aa094f0-2f88-4e16-ba8c-5652026e47e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import (\n",
    "#     roc_curve, roc_auc_score,\n",
    "#     precision_recall_curve, average_precision_score,\n",
    "#     classification_report, confusion_matrix\n",
    "# )\n",
    "# # === 2. ROC Curve & AUC ===\n",
    "# y_prob = log_reg.predict_proba(X_test)[:, 1]\n",
    "# #\n",
    "# fpr, tpr, thresholds = roc_curve(y_test, y_prob)\n",
    "# roc_auc = roc_auc_score(y_test, y_prob)\n",
    "\n",
    "# plt.figure(figsize=(6, 5))\n",
    "# plt.plot(fpr, tpr, label=f'ROC Curve (AUC = {roc_auc:.2f})')\n",
    "# plt.plot([0, 1], [0, 1], 'k--', label=\"Random Guess\")\n",
    "# plt.xlabel(\"False Positive Rate\")\n",
    "# plt.ylabel(\"True Positive Rate (Recall)\")\n",
    "# plt.title(\"ROC Curve\")\n",
    "# plt.legend(loc=\"lower right\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12c82da2-86ff-412c-87e3-6808648889eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # === 3. Precision-Recall Curve ===\n",
    "# precision, recall, pr_thresholds = precision_recall_curve(y_test, y_prob)\n",
    "# ap_score = average_precision_score(y_test, y_prob)\n",
    "\n",
    "# plt.figure(figsize=(6, 5))\n",
    "# plt.plot(recall, precision, label=f'PR Curve (AP = {ap_score:.2f})')\n",
    "# plt.xlabel(\"Recall\")\n",
    "# plt.ylabel(\"Precision\")\n",
    "# plt.title(\"Precision-Recall Curve\")\n",
    "# plt.legend(loc=\"upper right\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c53fdd04-48d0-4154-8017-8db9ff889522",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import (\n",
    "    roc_curve, roc_auc_score,\n",
    "    precision_recall_curve, average_precision_score,\n",
    "    classification_report, confusion_matrix\n",
    ")\n",
    "# Predicted probabilities for class 0 (defaulters)\n",
    "y_scores = log_reg.predict_proba(X_test)[:, 0]\n",
    "\n",
    "# ----------------------------\n",
    "# 1. PR Curve Method\n",
    "# ----------------------------\n",
    "precision, recall, thresholds_pr = precision_recall_curve(y_test, y_scores, pos_label=0)\n",
    "f1_scores = 2 * (precision * recall) / (precision + recall + 1e-8)\n",
    "best_idx_pr = np.argmax(f1_scores)\n",
    "threshold_pr = thresholds_pr[best_idx_pr]\n",
    "\n",
    "print(\"Optimal Threshold (PR Curve, max F1) for defaulters:\", threshold_pr)\n",
    "print(\"Precision:\", precision[best_idx_pr])\n",
    "print(\"Recall:\", recall[best_idx_pr])\n",
    "print(\"F1:\", f1_scores[best_idx_pr])\n",
    "\n",
    "# ----------------------------\n",
    "# 2. ROC Curve Method\n",
    "# ----------------------------\n",
    "fpr, tpr, thresholds_roc = roc_curve(y_test, y_scores, pos_label=0)\n",
    "j_scores = tpr - fpr\n",
    "best_idx_roc = np.argmax(j_scores)\n",
    "threshold_roc = thresholds_roc[best_idx_roc]\n",
    "\n",
    "print(\"\\nOptimal Threshold (ROC Curve, Youden's J) for defaulters:\", threshold_roc)\n",
    "print(\"TPR (Recall):\", tpr[best_idx_roc])\n",
    "print(\"FPR:\", fpr[best_idx_roc])\n",
    "\n",
    "# ----------------------------\n",
    "# 3. Compare thresholds visually\n",
    "# ----------------------------\n",
    "plt.figure(figsize=(12,5))\n",
    "\n",
    "# PR Curve\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(recall, precision, label='PR Curve')\n",
    "plt.scatter(recall[best_idx_pr], precision[best_idx_pr], color='red', label='Optimal F1')\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Precision-Recall Curve')\n",
    "plt.legend()\n",
    "\n",
    "# ROC Curve\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(fpr, tpr, label='ROC Curve')\n",
    "plt.scatter(fpr[best_idx_roc], tpr[best_idx_roc], color='red', label=\"Optimal J\")\n",
    "plt.plot([0,1],[0,1],'--', color='gray')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate (Recall)')\n",
    "plt.title('ROC Curve')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# ----------------------------\n",
    "# 4. Predictions using PR optimal threshold\n",
    "# ----------------------------\n",
    "y_pred_optimal = (y_scores >= threshold_pr).astype(int)\n",
    "cm = confusion_matrix(y_test, y_pred_optimal)\n",
    "print(\"\\nConfusion Matrix (PR Threshold):\\n\", cm)\n",
    "print(\"\\nClassification Report (PR Threshold):\\n\", classification_report(y_test, y_pred_optimal))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b128398-7eb1-43e4-8c4c-43188784eed7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
